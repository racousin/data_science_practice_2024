import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.linear_model import LinearRegression, LogisticRegression, Lasso, Ridge, RidgeClassifier
from sklearn.metrics import mean_squared_error, accuracy_score
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, BaggingRegressor, StackingRegressor, StackingClassifier
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.svm import SVR, SVC
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import StratifiedKFold, KFold
from sklearn.metrics import make_scorer
from sklearn.base import RegressorMixin, ClassifierMixin, BaseEstimator
from sklearn.ensemble import VotingClassifier
from skopt import BayesSearchCV
from skopt.space import Real, Integer, Categorical
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor

from xgboost import XGBClassifier, XGBRegressor
from lightgbm import LGBMClassifier, LGBMRegressor





import requests

# URLs of the files
train_data_url = 'https://www.raphaelcousin.com/modules/module6/exercise/module6_exercise_train.csv'
test_data_url = 'https://www.raphaelcousin.com/modules/module6/exercise/module6_exercise_test.csv'

# Function to download a file
def download_file(url, file_name):
    response = requests.get(url)
    response.raise_for_status()  # Ensure we notice bad responses
    with open(file_name, 'wb') as file:
        file.write(response.content)
    print(f'Downloaded {file_name} from {url}')

# Downloading the files
download_file(train_data_url, 'module6_exercise_train.csv')
download_file(test_data_url, 'module6_exercise_test.csv')


data_train = pd.read_csv('module6_exercise_train.csv', index_col='index')
data_test = pd.read_csv('module6_exercise_test.csv', index_col='index')





data_train


data_test


data_train.describe()


data_train.isnull().sum()


plt.figure(figsize=(10, 6))
sns.histplot(data_train['end_of_day_return'], bins=50, kde=True)
plt.title('Distribution of End of Day Return')
plt.xlabel('End of Day Return')
plt.ylabel('Frequency')
plt.show()


y = data_train.pop('end_of_day_return')
X = data_train.copy()
X_tt = data_test.copy()


def weighted_accuracy(y_true, y_pred):
    weights = np.abs(y_true)
    
    # Compute the sign of true and predicted values
    sign_true = np.sign(y_true)
    sign_pred = np.sign(y_pred)
    
    # Correct predictions where the sign of the true and predicted values match
    correct_predictions = sign_true == sign_pred
    
    # Compute the weighted accuracy
    weighted_acc = np.sum(weights * correct_predictions) / np.sum(weights)
    
    return weighted_acc


# Function to plot the evaluation results
def plot_results(mse_train, mse_test, w_acc_train, w_acc_test):
    plt.figure(figsize=(12, 6))

    # MSE plot
    plt.subplot(1, 2, 1)
    plt.plot(mse_train, label="Train MSE", marker='o')
    plt.plot(mse_test, label="Test MSE", marker='o')
    plt.fill_between(range(len(mse_train)), np.min(mse_train), np.max(mse_train), color='blue', alpha=0.1)
    plt.fill_between(range(len(mse_test)), np.min(mse_test), np.max(mse_test), color='orange', alpha=0.1)
    plt.title("MSE over Folds")
    plt.xlabel("Fold")
    plt.ylabel("MSE")
    plt.legend()
    plt.grid(True)

    # weighted_accuracy plot
    plt.subplot(1, 2, 2)
    plt.plot(w_acc_train, label="Train weighted_accuracy", marker='o')
    plt.plot(w_acc_test, label="Test weighted_accuracy", marker='o')
    plt.fill_between(range(len(w_acc_train)), np.min(w_acc_train), np.max(w_acc_train), color='blue', alpha=0.1)
    plt.fill_between(range(len(w_acc_test)), np.min(w_acc_test), np.max(w_acc_test), color='orange', alpha=0.1)
    plt.title("weighted_accuracy over Folds")
    plt.xlabel("Fold")
    plt.ylabel("weighted_accuracy")
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.show()

def plot_multi_model_results(results):
    # Set up the plot
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 20))
    
    # Colors for train and test
    train_color = 'skyblue'
    test_color = 'lightgreen'
    
    # Plot MSE
    ax1.set_title('Mean Squared Error (MSE) Comparison', fontsize=16)
    ax1.set_ylabel('MSE', fontsize=12)
    ax1.set_xlabel('Models', fontsize=12)
    ax1.grid(True, linestyle='--', alpha=0.7)
    
    # Plot weighted_accuracy
    ax2.set_title('weighted_accuracy Comparison', fontsize=16)
    ax2.set_ylabel('weighted_accuracy', fontsize=12)
    ax2.set_xlabel('Models', fontsize=12)
    ax2.grid(True, linestyle='--', alpha=0.7)
    
    x = np.arange(len(results))
    width = 0.35
    
    for i, (model_name, scores) in enumerate(results.items()):
        # MSE
        mse_train = scores['mse_train']
        mse_test = scores['mse_test']
        
        ax1.bar(x[i] - width/2, np.mean(mse_train), width, label='Train' if i == 0 else "", 
                color=train_color, alpha=0.7)
        ax1.bar(x[i] + width/2, np.mean(mse_test), width, label='Test' if i == 0 else "", 
                color=test_color, alpha=0.7)
        
        ax1.errorbar(x[i] - width/2, np.mean(mse_train), 
                     yerr=[[np.mean(mse_train)-np.min(mse_train)], [np.max(mse_train)-np.mean(mse_train)]], 
                     fmt='none', ecolor='black', capsize=5)
        ax1.errorbar(x[i] + width/2, np.mean(mse_test), 
                     yerr=[[np.mean(mse_test)-np.min(mse_test)], [np.max(mse_test)-np.mean(mse_test)]], 
                     fmt='none', ecolor='black', capsize=5)
        
        # weighted_accuracy
        w_acc_train = scores['w_acc_train']
        w_acc_test = scores['w_acc_test']
        
        ax2.bar(x[i] - width/2, np.mean(w_acc_train), width, label='Train' if i == 0 else "", 
                color=train_color, alpha=0.7)
        ax2.bar(x[i] + width/2, np.mean(w_acc_test), width, label='Test' if i == 0 else "", 
                color=test_color, alpha=0.7)
        
        ax2.errorbar(x[i] - width/2, np.mean(w_acc_train), 
                     yerr=[[np.mean(w_acc_train)-np.min(w_acc_train)], [np.max(w_acc_train)-np.mean(w_acc_train)]], 
                     fmt='none', ecolor='black', capsize=5)
        ax2.errorbar(x[i] + width/2, np.mean(w_acc_test), 
                     yerr=[[np.mean(w_acc_test)-np.min(w_acc_test)], [np.max(w_acc_test)-np.mean(w_acc_test)]], 
                     fmt='none', ecolor='black', capsize=5)
    
    ax1.set_xticks(x)
    ax1.set_xticklabels(results.keys(), rotation=45, ha='right')
    ax2.set_xticks(x)
    ax2.set_xticklabels(results.keys(), rotation=45, ha='right')
    
    ax1.legend(loc='upper left')
    ax2.legend(loc='upper left')
    
    plt.tight_layout()
    plt.show()








model1 = LinearRegression()
kf = KFold(n_splits=7, shuffle=True, random_state=42)
mse_tr1 = []
mse_tt1 = []
wac_tr1 = []
wac_tt1 = []
for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    model1.fit(X_train, y_train)
    mse_tt = np.mean((y_test - model1.predict(X_test))**2)
    mse_tr = np.mean((y_train - model1.predict(X_train))**2)
    wac_tr = weighted_accuracy(y_train,model1.predict(X_train))
    wac_tt = weighted_accuracy(y_test,model1.predict(X_test))
    wac_tr1.append(wac_tr)
    wac_tt1.append(wac_tt)
    mse_tt1.append(mse_tt)
    mse_tr1.append(mse_tr)
    y_pred1 = model1.predict(X_test)

plot_results(mse_tr1, mse_tt1, wac_tr1, wac_tt1)







# Define the parameter distributions
param_space = {
    'n_estimators': Integer(10, 500),    
    'max_depth': Integer(1, 20),        
    'min_samples_split': Integer(2, 20), 
    'min_samples_leaf': Integer(1, 10), 
    'max_features': Real(0.1, 1.0, prior='uniform') 
}

# 创建随机森林分类器
rf = RandomForestClassifier(random_state=42)

# 使用贝叶斯搜索优化超参数
bayes_search = BayesSearchCV(
    estimator=rf,
    search_spaces=param_space,
    n_iter=10,       
    cv=5,        
    n_jobs=-1,   
    verbose=0,  
    random_state=42 
)

# 对训练数据进行拟合
bayes_search.fit(X, y > 0)  # 假设 `y > 0` 是二分类问题


model2 = bayes_search
kf = KFold(n_splits=7, shuffle=True, random_state=42)
mse_tr2 = []
mse_tt2 = []
wac_tr2 = []
wac_tt2 = []
for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    y_train_pred = model2.predict(X_train)
    y_test_pred = model2.predict(X_test)
    
    y_train_pred = y_train_pred.astype(np.int64)
    y_test_pred = y_test_pred.astype(np.int64)

    y_train = (y_train>0).astype(np.int64)
    y_test = (y_test>0).astype(np.int64)
    
    mse_tr = np.mean((y_train - y_train_pred)**2)
    mse_tt = np.mean((y_test - y_test_pred)**2)
    wac_tr = weighted_accuracy(y_train, y_train_pred)
    wac_tt = weighted_accuracy(y_test, y_test_pred)
    
    mse_tr2.append(mse_tr)
    mse_tt2.append(mse_tt)
    wac_tr2.append(wac_tr)
    wac_tt2.append(wac_tt)

plot_results(mse_tr2, mse_tt2, wac_tr2, wac_tt2)





param_space = {
    'n_estimators': Integer(10, 500),
    'max_depth': Integer(1, 20),
    'min_samples_split': Integer(2, 20),
    'min_samples_leaf': Integer(1, 20),
    'max_features': Real(0.1, 1.0, prior='uniform')
}

opt_reg = BayesSearchCV(
    RandomForestRegressor(),
    param_space,
    n_iter=50,
    cv=5,
    n_jobs=-1,
    verbose=0
)

# 模型拟合 
opt_reg.fit(X, y)


model3 = opt_reg
kf = KFold(n_splits=7, shuffle=True, random_state=42)
mse_tr3 = []
mse_tt3 = []
wac_tr3 = []
wac_tt3 = [] 
for train_index, test_index in kf.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    y_train_pred = model3.predict(X_train)
    y_test_pred = model3.predict(X_test)
    
    mse_tr = np.mean((y_train - y_train_pred)**2)
    mse_tt = np.mean((y_test - y_test_pred)**2)
    wac_tr = weighted_accuracy(y_train, y_train_pred)
    wac_tt = weighted_accuracy(y_test, y_test_pred)
    
    mse_tr3.append(mse_tr)
    mse_tt3.append(mse_tt)
    wac_tr3.append(wac_tr)
    wac_tt3.append(wac_tt)

plot_results(mse_tr3, mse_tt3, wac_tr3, wac_tt3)


y_pred = model3.predict(X_test)
y_pred.to_csv('submission.csv', index=True)



